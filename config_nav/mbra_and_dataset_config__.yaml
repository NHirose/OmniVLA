# parameters for MBRA
context_size: 5 #history of image
len_traj_pred: 8 #action length
learn_angle: True
obs_encoder: efficientnet-b0
obs_encoding_size: 1024
late_fusion: False
mha_num_attention_heads: 4
mha_num_attention_layers: 4
mha_ff_dim_factor: 4

# parameters for training dataset
image_size: [96, 96] # width, height
context_type: temporal
normalize: True
num_workers: 10

#For GNM dataset
datasets_CAST:
  path: /media/noriaki/Noriaki_Data/CAST_dataset/

datasets_frodobots:
  root: /media/noriaki/Noriaki_Data
  horizon_short: 20
  horizon_long: 100  
  frodobot:
    train: 11434305
    test: 11434305
    negative_mining: True

datasets_bdd:    
  train: /media/noriaki/Noriaki_Data/Learning-to-Drive-Anywhere-with-MBRA/data_splits/bdd/train/
  test: /media/noriaki/Noriaki_Data/Learning-to-Drive-Anywhere-with-MBRA/data_splits/bdd/test/
  image: /media/noriaki/Noriaki_Data/BDD_dataset
  pickle: /media/noriaki/Noriaki_Data/BDD_dataset_pickle
  backside: False
  aug_seq: False
  only_front: True
  waypoint_spacing: 0.12      
    
datasets_gnm:
  distance:
    min_dist_cat: 0
    max_dist_cat: 20
  action:
    min_dist_cat: 3
    max_dist_cat: 20

  recon:
    data_folder: /media/noriaki/Noriaki_Data2/visualnav-transformer/gnm_dataset/recon
    train: /home/noriaki/Documents/Learning-to-Drive-Anywhere-via-MBRA/data_splits/recon/train/ # path to train folder with traj_names.txt
    test: /home/noriaki/Documents/Learning-to-Drive-Anywhere-via-MBRA/data_splits/recon/test/ # path to test folder with traj_names.txt
    end_slack: 3 # because many trajectories end in collisions
    goals_per_obs: 1 # how many goals are sampled per observation
    negative_mining: True # negative mining from the ViNG paper (Shah et al.)
  go_stanford:
    data_folder: /media/noriaki/Noriaki_Data2/visualnav-transformer/gnm_dataset/go_stanford # datasets/stanford_go_new
    train: /home/noriaki/Documents/Learning-to-Drive-Anywhere-via-MBRA/data_splits/go_stanford/train/
    test: /home/noriaki/Documents/Learning-to-Drive-Anywhere-via-MBRA/data_splits/go_stanford/test/
    end_slack: 0
    goals_per_obs: 2 # increase dataset size
    negative_mining: True
  cory_hall:
    data_folder: /media/noriaki/Noriaki_Data2/visualnav-transformer/gnm_dataset/cory_hall
    train: /home/noriaki/Documents/Learning-to-Drive-Anywhere-via-MBRA/data_splits/cory_hall/train/
    test: /home/noriaki/Documents/Learning-to-Drive-Anywhere-via-MBRA/data_splits/cory_hall/test/
    end_slack: 3 # because many trajectories end in collisions
    goals_per_obs: 1
    negative_mining: True
  tartan_drive:
    data_folder: /media/noriaki/Noriaki_Data2/visualnav-transformer/gnm_dataset/tartan_drive
    train: /home/noriaki/Documents/Learning-to-Drive-Anywhere-via-MBRA/data_splits/tartan_drive/train/
    test: /home/noriaki/Documents/Learning-to-Drive-Anywhere-via-MBRA/data_splits/tartan_drive/test/
    end_slack: 3 # because many trajectories end in collisions
    goals_per_obs: 1
    negative_mining: True
  sacson:
    data_folder: /media/noriaki/Noriaki_Data2/visualnav-transformer/gnm_dataset/sacson
    train: /home/noriaki/Documents/Learning-to-Drive-Anywhere-via-MBRA/data_splits/sacson/train/
    test: /home/noriaki/Documents/Learning-to-Drive-Anywhere-via-MBRA/data_splits/sacson/test/
    end_slack: 3 # because many trajectories end in collisions
    goals_per_obs: 1
    negative_mining: True

  seattle:
    data_folder: /media/noriaki/Noriaki_Data2/visualnav-transformer/gnm_dataset/seattle/
    train: /home/noriaki/Documents/Learning-to-Drive-Anywhere-via-MBRA/data_splits/seattle/train/
    test: /home/noriaki/Documents/Learning-to-Drive-Anywhere-via-MBRA/data_splits/seattle/test/
    end_slack: 0
    goals_per_obs: 1
    negative_mining: True
  scand:
    data_folder: /media/noriaki/Noriaki_Data2/visualnav-transformer/gnm_dataset/scand/
    train: /home/noriaki/Documents/Learning-to-Drive-Anywhere-via-MBRA/data_splits/scand/train/
    test: /home/noriaki/Documents/Learning-to-Drive-Anywhere-via-MBRA/data_splits/scand/test/
    end_slack: 0
    goals_per_obs: 1
    negative_mining: True

datasets_lelan:  
  go_stanford4:
    train: /media/noriaki/Noriaki_Data/dataset/lelan_gs4/train/
    test: /media/noriaki/Noriaki_Data/dataset/lelan_gs4/test/
    image: /media/noriaki/Noriaki_Data/dataset/dataset_LeLaN_gs4/
    pickle: /media/noriaki/Noriaki_Data/dataset/dataset_LeLaN_gs4/
    backside: False
    aug_seq: False
    only_front: False
            
  sacson:
    train: /media/noriaki/Noriaki_Data/dataset/lelan_sacson/train/
    test: /media/noriaki/Noriaki_Data/dataset/lelan_sacson/test/
    image: /media/noriaki/Noriaki_Data/dataset/dataset_LeLaN_sacson/
    pickle: /media/noriaki/Noriaki_Data/dataset/dataset_LeLaN_sacson/
    backside: False
    aug_seq: False
    only_front: False
            
  go_stanford2:
    train: /media/noriaki/Noriaki_Data/dataset/lelan_gs2/train/
    test: /media/noriaki/Noriaki_Data/dataset/lelan_gs2/test/
    image: /media/noriaki/Noriaki_Data/dataset/dataset_LeLaN_gs2/
    pickle: /media/noriaki/Noriaki_Data/dataset/dataset_LeLaN_gs2/
    backside: False
    aug_seq: False
    only_front: False

  humanw:
    train: /media/noriaki/Noriaki_Data/dataset/lelan_humanw/train/
    test: /media/noriaki/Noriaki_Data/dataset/lelan_humanw/test/
    image: /media/noriaki/Noriaki_Data/dataset/dataset_LeLaN_humanwalk/
    pickle: /media/noriaki/Noriaki_Data/dataset/dataset_LeLaN_humanwalk/    
    backside: False
    aug_seq: False 
    only_front: True   

  youtube:
    train: /media/noriaki/Noriaki_Data/dataset/lelan_youtube/train/
    test: /media/noriaki/Noriaki_Data/dataset/lelan_youtube/test/
    image: /media/noriaki/Noriaki_Data/dataset/dataset_LeLaN_youtube/
    pickle: /media/noriaki/Noriaki_Data/dataset/dataset_LeLaN_youtube/        
    backside: False
    aug_seq: False 
    only_front: True  
